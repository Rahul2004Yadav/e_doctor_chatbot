# Core deep learning and transformers
torch>=2.0.0
transformers>=4.38.0
bitsandbytes>=0.43.0
accelerate>=0.25.0

# Parameter-efficient fine-tuning
peft>=0.10.0
unsloth @ git+https://github.com/unslothai/unsloth.git

# Training and evaluation
trl>=0.7.10
datasets>=2.18.0
evaluate>=0.4.1

# Experiment tracking
wandb>=0.16.0

# Hugging Face Hub login
huggingface_hub>=0.23.0
